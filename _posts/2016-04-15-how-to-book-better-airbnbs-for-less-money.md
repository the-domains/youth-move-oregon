---
datePublished: '2016-07-09T13:13:12.683Z'
sourcePath: _posts/2016-04-15-how-to-book-better-airbnbs-for-less-money.md
inFeed: true
isBasedOnUrl: >-
  https://www.thrillist.com/tech/nation/airbnb-hacks-how-to-find-better-cheaper-listings/travel
authors: []
hasPage: false
keywords:
  - thrillist
  - airbnb
  - castle
  - nyc
  - airbnb-er
  - mcgauley
  - detail
  - back-and-forth
  - listing
  - crucial
related: []
author:
  - name: Rafferty
    url: 'https://www.youthmoveoregon.com'
    avatar: {}
  - name: '@jwmcgauley'
    url: 'https://www.twitter.com/@jwmcgauley'
    avatar: {}
dateModified: '2016-07-09T13:13:12.574Z'
title: 'Facebook has been redesigned for profit: and teen suicide is a consequence. '
app_links:
  - namespace: twitter
    type: iphone
    id: id356278120
    name: Thrillist
publisher:
  name: thrillist
  domain: www.thrillist.com
  url: 'https://www.thrillist.com'
  favicon: 'https://www.thrillist.com/thrillist_favicon.png'
description: ' In the internet age, the connection between youth suicide and social media is indisputable. In the past decade alone there have been a handful of high-profile cyberbullicides--a term coined by researchers at the Cyberbullying Research Center to describe suicides directly or indirectly caused by cyberbullying. Tragically, a number of these suicides have been filmed or even streamed live on the internet: In 2008, Abraham Biggs, a community college student from Florida posted a suicide note to BodyBuilding.com before broadcasting his suicide over the now-defunct live-streaming website Justin.tv. His peers responded with anything but compassion; instead, some watchers encouraged him to “do it for real”; that is to take the lethal dose of medications he’d concocted, none of the viewers watching called the police until he was already unconscious. '
inLanguage: en
inNav: false
starred: false
_context: 'http://schema.org'
_type: MediaObject

---
# Facebook has been redesigned for profit: and teen suicide is a consequence. ![When young people are at the highest risk, could their final cry for help be muted by "advanced algorithms"?](https://s3-us-west-2.amazonaws.com/the-grid-img/p/ac49eb0380eb5ce40446c86676577665f94fc953.jpg)

In the internet age, the connection between youth suicide and social media is indisputable. In the past decade alone there have been a handful of high-profile cyberbullicides--a term coined by researchers at the Cyberbullying Research Center to describe suicides directly or indirectly caused by cyberbullying. Tragically, a number of these suicides have been filmed or even streamed live on the internet: In 2008, Abraham Biggs, a community college student from Florida posted a suicide note to BodyBuilding.com before broadcasting his suicide over the now-defunct live-streaming website Justin.tv. His peers responded with anything but compassion; instead, some watchers encouraged him to "do it for real"; that is to take the lethal dose of medications he'd concocted, none of the viewers watching called the police until he was already unconscious. 

Anyone working directly with youth involved in the mental health system will tell you that stories like this are anything but isolated incidents. The questions that arise in the wake of youth suicides like Biggs' are many, but the most important, perhaps, for youth workers and staff of social media sites alike, is how to make social media platforms safer for young people at risk of suicide and self-harm. Should we hold media giants like Facebook, Instagram, and Twitter responsible for the safety of their users? Could Biggs' life have been saved if either of the sites he used to reach out for help had features in place designed to recognize his cry for help? And furthermore, are there features currently in place that could work to marginalize young people like Biggs, rather than support them? 

Since 2009, for example, Facebook has been using an algorithmic model for their Newsfeed, one based on how often and how users interact with one another. This algorithm operates on popularity, and is governed by likes, shares, and comments. PostRocket estimates that the average Facebook post only reaches 16% of a user's friends. As those friends like, share, or comment on that post, that percentage rises. In this sense, Facebook relies on its users to designate what content is most relevant to them, but what does that mean for youth who use Facebook to reach out for help in times of crisis? It seems unlikely that a young person's post about suicide would be "liked" or "shared," and while it seems more probable that concerned friends and family might comment on it, they may never get the chance to do so if the post isn't "popular" enough to show up on their feeds. 

Ultimately, it's clear that youth in crisis are a blind spot in social media circles: a demographic lost in the shuffle of social media giants competing to monetize their platforms. And the final irony: networking sites like Facebook, designed (at least perfunctorily) to connect people, end up putting youth at risk precisely when they need connections the most. Why isn't Facebook being direct with it's users about how many of their friends will see a post? Answer below...